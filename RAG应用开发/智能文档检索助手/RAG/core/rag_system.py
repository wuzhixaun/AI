from langchain_core.prompts import PromptTemplate
import uuid
from langchain_openai import ChatOpenAI


class RAGSystem:
    def __init__(self, config, db_manager, vector_store):
        self.config = config
        self.db_manager = db_manager
        self.vector_store = vector_store

        # 创建 llm
        self.llm = ChatOpenAI(
            model=self.config.LLM_MODEL,
            api_key=self.config.OPENAI_API_KEY,
            base_url=self.config.OPENAI_BASE_URL
        )

        # RAG提示模板
        self.rag_prompt = PromptTemplate(
            template="""
            你是一个智能助手。请基于以下上下文信息回答用户的问题。如果上下文中没有相关信息，请诚实地说明。

            上下文信息：
            {context}

            历史对话信息：
            {chat_history}

            用户问题:
            {question}

            请提供准确、有帮助的回答:
            """,
            input_variables=["context", "chat_history", "question"]
        )

    def generate_session_id(self):
        """生成会话id"""
        return str(uuid.uuid4())

    def chat_with_document(self, question, document_ids, session_id):
        """基于文档的 RAG 对话"""
        try:
            # 创建检索器
            retriever = self.vector_store.create_retriever(use_compression=True)

            # 检索相关文档
            retrieved_docs = retriever.invoke(question)

            # 获取父文档以提供更完整的上下文
            parent_docs = self.vector_store.get_parent_documents(retrieved_docs)

             # 构建上下文
            context = "\n\n".join(parent_docs)
            print("最终检索的上下文：", context)
            # 获取历史对话
            chat_history = self.db_manager.get_chat_history(session_id)
            history_text = "\n".join([
                f"用户: {chat.user_message}\n助手: {chat.assistant_message}"
                for chat in chat_history[-3:]  # 最近3轮对话
            ])

            # 构建完整提示
            full_prompt = self.rag_prompt.format(
                context=context,
                chat_history=history_text,
                question=question
            )

            # 生成回答
            response = self.llm.invoke(full_prompt)
            answer = response.content


             # 保存对话历史
            self.db_manager.save_chat_history(
                session_id=session_id,
                user_message=question,
                assistant_message=answer,
                document_ids=",".join(map(str, document_ids))
            )

            return answer, retrieved_docs

        except Exception as e:
            print(f"chat_with_document error: {e}")
            raise e


    def normal_chat(self,question,session_id):
        """普通对话"""
        try:
            # 获取历史对话
            chat_history = self.db_manager.get_chat_history(session_id)

             # 构建对话上下文
            messages = []

            for chat in chat_history[-5:]:  # 最近5轮对话
                messages.append(f"Human: {chat.user_message}")
                messages.append(f"Assistant: {chat.assistant_message}")
            
            # 添加当前问题
            messages.append(f"Human: {question}")

            conversation_context = "\n".join(messages)

             # 生成回答
            response = self.llm.invoke(conversation_context + "\nAssistant:")
            answer = response.content

            # 保存对话历史
            self.db_manager.save_chat_history(
                session_id=session_id,
                user_message=question,
                assistant_message=answer
            )

            return answer
        except Exception as e:
            error_msg = f"普通对话出错: {str(e)}"
            print(error_msg)
            return error_msg